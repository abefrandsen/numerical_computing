\lab{Algorithms}{Elementary Matrices}{Elementary Matrices}

\objective{In this section we will use elementary matrices to find the reduced row echelon form of a matrix (RREF) and to find the LU decomposition.}

In Linear algebra there are 3 elementary row operations: switching two rows, multiplying a row by a constant, and adding a multiple of one row to another row.  We carry out each of these operations with a corresponding elementary matrix.  These matrices are easy to construct. Suppose $A$ is an $m \times n$ matrix and you want to perform one of the three elementary operations on $A$. You can do this be constructing the $m \times m$ identity matrix, $I$, performing the elementary row operation on $I$ to obtain $E$ and then multiplying $EA$.  For example, consider the matrix
\[
A = \begin{pmatrix}
a_{11}&a_{12}&a_{13}&a_{14}\\
a_{21}&a_{22}&a_{23}&a_{24}\\
a_{31}&a_{32}&a_{33}&a_{34}
\end{pmatrix}
\]
If we want to swap the first two rows, we can left multiply the
matrix $A$ by:
\[
E = \begin{pmatrix}
0&1&0\\
1&0&0\\
0&0&1
\end{pmatrix},
\]
then
\[
E A =
\begin{pmatrix}
a_{21}&a_{22}&a_{23}&a_{24}\\
a_{11}&a_{12}&a_{13}&a_{14}\\
a_{31}&a_{32}&a_{33}&a_{34}
\end{pmatrix}.
\]
E in this case is called a type I matrix.  A MATLAB function that creates this elementary matrix is

\begin{verbatim}
function out = type1m(n,j,k)
%
% Type I Elementary Matrix
%

out = eye(n); out(j,j)=0; out(k,k)=0; out(k,j)=1; out(j,k)=1;
\end{verbatim}

Now let's examine the next row operation.  If we want to multiply,
say, the second row of $A$ by the constant $b$, we can left multiply
the matrix $A$ by the following matrix:
\[
\tilde{E} = \begin{pmatrix}
1&0&0\\
0&b&0\\
0&0&1
\end{pmatrix}.
\]
Then
\[
\tilde{E} A =
\begin{pmatrix}
a_{11}&a_{12}&a_{13}&a_{14}\\
b a_{21}&b a_{22}&b a_{23}&b a_{24}\\
a_{31}&a_{32}&a_{33}&a_{34}
\end{pmatrix}.
\]
$\tilde{E}$ is called a type II matrix.  The MATLAB code that creates a type II matrix is
\begin{verbatim}
function out = type2m(n,j,a)
%
% Type II Elementary Matrix
%

out = eye(n); out(j,j)=a;
\end{verbatim}

Now let's examine the last row operation.  If we want to multiply,
say, the first row of $A$ by a constant $c$ and add it to the second
row, we can left multiply the matrix $A$ by the following matrix:
\[
\widehat{E} = \begin{pmatrix}
1&0&0\\
c&1&0\\
0&0&1
\end{pmatrix}.
\]
Then
\[
\widehat{E} A =
\begin{pmatrix}
a_{11}&a_{12}&a_{13}&a_{14}\\
c a_{11} + a_{21}&c a_{12} + a_{22}&c a_{13} + a_{23}&c a_{14} + a_{24}\\
a_{31}&a_{32}&a_{33}&a_{34}
\end{pmatrix}.
\]
$\widehat{E}$ is called a type III matrix.  The MATLAB function that creates this elementary matrix is
\begin{verbatim}
function out = type3m(n,j,k,c)
%
% Type III Elementary Matrix
%
out = eye(n); out(j,k)=c;
\end{verbatim}

\section*{Programming Row Reduction}

A fundamental problem in linear algebra is using matrix representations to solve systems of linear equations.  In this section, we do this by using elementary matrices to reduce a matrix into ``row echelon form'' (REF), as opposed to ``reduced row echelon form'' (RREF).  We remark that to solve a linear system, it is actually faster computationally to use REF and then finish with back-substitution, than it is to use RREF.  Consider the following matrix: 

\[
\begin{pmatrix}
4&5&6&3 \\
2&4&6&4 \\
7&8&0&5
\end{pmatrix}
\]

By iteratively left multiplying by elementary matrices, we can reduce as follows:

\begin{verbatim}
>> A = [4 5 6 3; 2 4 6 4; 7 8 0 5]

>> B = type3m(3,2,1,-A(2,1)/A(1,1)) * A

>> C = type3m(3,3,1,-B(3,1)/B(1,1)) * B

>> D = type3m(3,3,2,-C(3,2)/C(2,2)) * C
\end{verbatim}
To complete REF we would need to divide each row by its leading
coefficient.  We can do that using Type II matrices.  We leave it to
you to carry this out.

\begin{problem}
Write a MATLAB function called {\tt myref}, which takes as input an
$n\times (n+1)$ matrix and performs the above naive row reduction
using elementary matrices (REF not RREF).
\end{problem}

\section*{LU Decomposition}

Again, consider the matrix $A$. By iteratively left multiplying by
elementary matrices, we reduce as follows:

\begin{verbatim}
>> A = [4 5 6 3; 2 4 6 4; 7 8 0 5]

>> E1 = type3m(3,2,1,-A(2,1)/A(1,1))

>> B = E1 * A

>> E2 = type3m(3,3,1,-B(3,1)/B(1,1))

>> C = E2 * B

>> E3 =  type3m(3,3,2,-C(3,2)/C(2,2))

>> U = E3 * C
\end{verbatim}
Note that we have reduced the above matrix into upper-triangular
form, denoted as $U$.  Hence, we have
\[
U = E_3 E_2 E_1 A.
\]
Since the elementary matrices are invertible, we also have
\[
(E_3 E_2 E_1)^{-1} U =  A.
\]
This can be re-written as
\[
E_1^{-1} E_2^{-1} E_3^{-1} U =  A.
\]
Then we define $L$ to be
\[
L = E_1^{-1} E_2^{-1} E_3^{-1},
\]
which yields $L U = A$.  We carry this out in MATLAB:
\begin{verbatim}
>> L = inv(E1) * inv(E2) * inv(E3)

>> L * U
\end{verbatim}
What makes $LU$ decomposition so easy is that the inverses of
elementary matrices are elementary matrices.  For example, the
inverse of a Type 3 elementary matrix is the same matrix with the
opposite sign in the $(j,k)$ entry.  In the above problem, we have:
\begin{verbatim}
>> L = type3m(3,2,1,A(2,1)/A(1,1)) * ...
       type3m(3,3,1,B(3,1)/B(1,1)) * ...
       type3m(3,3,2,C(3,2)/C(2,2))
\end{verbatim}
Note that the minus signs are gone.  Doing it this way, we don't
have to actually invert anything to compute $L$.  This makes the
computation much faster.

\section*{Why Should I Care?}

The LU Decomposition isn't very useful when doing matrix computation
by hand.  It is, however, very important in scientific computation
for the following reasons:
\begin{itemize}
\item If you want to solve the matrix equation $A x = b$, for several different $b's$, you can replace $A$ with $L$ and $U$, giving $L U x = b$.  Then solve the equations $L y = b$ and $U x = y$, using forward and backward substitution, respectively.  This is actually faster than solving them with row reduction.
\item The $LU$ decomposition allows quick computation of both inverses and determinants.
\item For very large matrices the $LU$ decomposition is crucial.  Indeed one can perform the $LU$ decomposition on a given matrix $A$ without needing additional space, that is, the program actually over-writes $A$ with $L$ and $U$.  Note that since the diagonal of $L$ are all ones, they don't need to be stored, and so the upper diagonal (including the diagonal) is $U$ and the lower diagonal (not including the diagonal) is $L$.
\end{itemize}

\begin{problem}
Write a MATLAB function called {\tt mylu}, which takes as input
a random $n\times n$ matrix, performs the LU decomposition, and
returns $L$ and $U$.  To verify that it works, multiply $L$ and $U$
back together again to get $A$. Note: you should not use the {\tt inv} function when you do this. You should only use the elementary matrices that we just created.
\end{problem}

\begin{problem}
Write a MATLAB function called {\tt mydet}, which uses {\tt
mylu} to find the determinant of $A$.
\end{problem}
