\lab{Applications}{Eigenvalues and Graph Theory}{Eigenvalues and Graph Theory}
\label{Ch:EigGraph}

\objective{Understand some basic applications of Eigenvalues to graph theory}

Recall from chapter \ref{Ch:Markov} that we can represent the information contained in a graph with a matrix, which we call an adjacency matrix.  In this lab we will be investigating the sorts of things that we can discover about a graph by examining the spectrum of its adjacency matrix.

We begin by first looking at the definition of the Laplacian of an unweighted graph:
\begin{definition}  The Laplacian of an unweighted graph is given by the following.  Let $D$ be a diagonal matrix with
\[
D_{ii} = \mbox{ Degree of node $i$}
\]
and let $A$ be the adjacency matrix of the graph.  Then the graph Laplacian $Q$ is given by
\[
Q = A - D
\]
\end{definition}

We will be examining the spectrum of the Laplacian matrix of a graph and the surprising things we can find out about a graph by simply examining this spectrum.  Before delving too deep though, we examine why we call this construction the ``graph Laplacian.''

Recall that the Laplacian operator of a function is given by
\[
\Delta f(x,y) = \frac{\partial ^2 f}{\partial x^2} + \frac{\partial ^2 f}{\partial y^2}
\]
When we are computing numerical derivatives, this operator can be approximated by what is called a finite difference scheme (see Labs \ref{Ch:Numerical Derivatives} and \ref{Ch:Multivariate Finite Difference Schemes} for a more extensive treatment of the subject) on a mesh of function values.  A simple numerical approximation in this case would be
\[
\Delta f(x_i,y_j) = f(x_{i-1},y_j) - 2f(x_i,y_j) + f(x_{i+1},y_j) + f(x_i,y_{j-1}) - 2f(x_i,y_j) + f(x_i,y_{j+1}
\]
{\bf EXPLAIN THIS BETTER}

\begin{problem} Consider the mesh in the previous example as a graph.  How are the finite difference scheme we mentioned similar to the graph Laplacian?
\end{problem}

Besides approximate the Laplacian operator, the graph Laplacian is also very useful for discovering the properties of graphs without exhaustively searching through them.

{\bf TO DO}
\begin{itemize}
\item Discuss connectivity of graphs
\item Mention eigenvalues of Laplacian matrix and how they relate to connectivity.
\end{itemize}

\begin{problem}Write a MATLAB program that accepts an adjacency matrix as an argument that returns the Laplacian matrix and it's second smallest eigenvalue.  Run this program on several types of Matrices - what do you notice? (TRY THIS ON RANDOM MATRICES MAYBE?)
\end{problem}

{\bf TO DO}
\begin{itemize}
\item Discuess graph Laplacian of weighted graphs
\item Brief discussion of the optimization problem that is solved by the second smallest eigenvalue
\item Brief review of building sparse matrices
\item The image segmentation problem
\end{itemize}

\begin{problem}  Write a MATLAB program that solves the segmentation problem for small images.  Accept an image as an argument and return the partitions.  Remember that the Laplacian matrix will be very large but also very sparse.  Adjust your algorithm accordingly.  This may be a relatively slow algorithm, but what improvement do we have over a naive approach to solving this problem?
\end{problem}
